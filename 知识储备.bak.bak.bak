整理问题篇
数据库篇
MySQL数据库相关
MySQL有哪些常见的存储引擎？

索引的原理是什么？

MySQL三种日志分别起到什么作用？（redoLog，undoLog，binLog）

为什么选择B+树索引？

什么情况下会出现索引失效？

如何查看执行计划？

如何优化SQL查询？

MySQL主从复制原理？

数据库死锁的原因？如何快速定位并解决？

事务隔离级别
事务有哪些隔离级别？

每种隔离级别会导致什么问题？

mysql 和 oracle默认情况下分别采用哪种隔离级别？

mysql如何解决幻读的？

中间件篇
MQ的相关问题
你用过消息队列吗？用了哪个消息队列？

在使用MQ的时候怎么确保消息 100% 不丢失？

怎么解决消息的重复消费问题？

如何实现顺序消息？

如何解决引入消息后的事务问题？

分库分表相关问题
你用过分库分表吗？

如何实现单个维度的非sharding-key 的查询问题？比如通过userID 作为 sharding-key，那么如何实现基于userName进行查询？（映射法、基因法）

如何实现多个维度的多个字段非 sharding-key 如何查询？时间、用户名、类别等...

多维度查询需要配合其他查询引擎，那么如何实现数据同步？如何保证双写的一致性？

很多情况下并不是一开始就实现分库分表，等我们需要分库分表的时候如何进行数据迁移？

Redis
用过Redis吗？Redis支持哪些常见的数据结构？

Redis的线程模型

Redis如何保证数据不丢失的（如何实现持久化）？

AOF 和 RDB的实现原理？

Redis如何实现高可用？

什么是缓存穿透，缓存击穿，缓存雪崩？分别如何预防解决？

分布式锁相关问题
用过分布式锁吗？用什么实现的分布式锁？

有没有用过基于redis分布式锁？有没有用过基于Zookeeper的分布式锁？

如何给锁设置合理的加锁时间？锁超时了怎么办？Redisson看门狗的原理？

Redis如何解决集群情况下分布式锁的可靠性？

RedLock算法的原理？

并发编程篇
锁相关
说一下synchronized 底层实现原理？

说一下synchronized、volatile、CAS 的区别？

synchronized 和 Lock 有什么区别？

什么是CAS，CAS的原理？

CAS有什么缺点？如何解决CAS中常见的ABA问题？

AQS的原理，AQS的实现过程是什么？

有没有用过读写锁ReentrantReadWriteLock，说一下ReentrantReadWriteLock的原理？

线程池相关
有哪几类线程池？如何创建线程池？

解释一下线程池的核心参数，线程池的执行过程？

如果提交任务时，线程池队列已满，这时候会发生什么？

线程池线上参数如何优化？

分布式篇
分布式理论
说说你对CAP理论的理解？

说说你用过的注册中心，分别使用了什么模型？（AP，CP）

说说你对BASE理论的理解？

分布式事务相关
如何解决分布式事务问题？你用过哪些解决分布式事务的方案？

说一下对2PC，3PC协议的理解？

有没有用过SEATA，SEATA的实现过程是什么？

如何基于MQ实现最终一致性？

实战篇
如何设计接口并保证他们的安全?

如何快速定位CPU溢出？

如何设计实现一个限流组件？

如何让系统能抗住预约抢购活动的流量压力？


SQL语句性能优化

1， 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。

2，应尽量避免在 where 子句中对字段进行 null 值判断，创建表时NULL是默认值，但大多数时候应该使用NOT NULL，或者使用一个特殊的值，如0，-1作为默 认值。

3，应尽量避免在 where 子句中使用!=或<>操作符， MySQL只有对以下操作符才使用索引：<，<=，=，>，>=，BETWEEN，IN，以及某些时候的LIKE。

4，应尽量避免在 where 子句中使用 or 来连接条件， 否则将导致引擎放弃使用索引而进行全表扫描， 可以 使用UNION合并查询：select id from t where num=10 union all select id from t where num=20

5，in 和 not in 也要慎用，否则会导致全表扫描，对于连续的数值，能用 between 就不要用 in 了：Select id from t where num between 1 and 3

6，下面的查询也将导致全表扫描：select id from t where name like ‘%abc%’ 或者select id from t where name like ‘%abc’若要提高效率，可以考虑全文检索。而select id from t where name like ‘abc%’ 才用到索引

7， 如果在 where 子句中使用参数，也会导致全表扫描。

8，应尽量避免在 where 子句中对字段进行表达式操作，应尽量避免在where子句中对字段进行函数操作

9,很多时候用 exists 代替 in 是一个好的选择：select num from a where num in(select num from b).用下面的语句替换：select num from a where exists(select 1 from b where num=a.num)

10,索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。

11,应尽可能的避免更新 clustered 索引数据列， 因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。

12，尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。

13，尽可能的使用 varchar/nvarchar 代替 char/nchar ， 因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。

14，最好不要使用”“返回所有：select from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。

15，尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。

16，使用表的别名(Alias)：当在SQL语句中连接多个表时,请使用表的别名并把别名前缀于每个Column上.这样一来,就可以减少解析的时间并减少那些由Column歧义引起的语法错误。

17，使用“临时表”暂存中间结果

简化SQL语句的重要方法就是采用临时表暂存中间结果，但是，临时表的好处远远不止这些，将临时结果暂存在临时表，后面的查询就在tempdb中了，这可以避免程序中多次扫描主表，也大大减少了程序执行中“共享锁”阻塞“更新锁”，减少了阻塞，提高了并发性能。

18，一些SQL查询语句应加上nolock，读、写是会相互阻塞的，为了提高并发性能，对于一些查询，可以加上nolock，这样读的时候可以允许写，但缺点是可能读到未提交的脏数据。使用 nolock有3条原则。查询的结果用于“插、删、改”的不能加nolock ！查询的表属于频繁发生页分裂的，慎用nolock ！使用临时表一样可以保存“数据前影”，起到类似Oracle的undo表空间的功能，能采用临时表提高并发性能的，不要用nolock 。

19，常见的简化规则如下：不要有超过5个以上的表连接（JOIN），考虑使用临时表或表变量存放中间结果。少用子查询，视图嵌套不要过深,一般视图嵌套不要超过2个为宜。

20，将需要查询的结果预先计算好放在表中，查询的时候再Select。这在SQL7.0以前是最重要的手段。例如医院的住院费计算。

21，用OR的字句可以分解成多个查询，并且通过UNION 连接多个查询。他们的速度只同是否使用索引有关,如果查询需要用到联合索引，用UNION all执行的效率更高.多个OR的字句没有用到索引，改写成UNION的形式再试图与索引匹配。一个关键的问题是否用到索引。

22，在IN后面值的列表中，将出现最频繁的值放在最前面，出现得最少的放在最后面，减少判断的次数。

23，尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。存储过程是编译好、优化过、并且被组织到一个执行规划里、且存储在数据库中的SQL语句，是控制流语言的集合，速度当然快。反复执行的动态SQL,可以使用临时存储过程，该过程（临时表）被放在Tempdb中。

24，当服务器的内存够多时，配制线程数量 = 最大连接数+5，这样能发挥最大的效率；否则使用 配制线程数量<最大连接数启用SQL SERVER的线程池来解决,如果还是数量 = 最大连接数+5，严重的损害服务器的性能。

25，查询的关联同写的顺序

select a.personMemberID, * from chineseresume a,personmember b where personMemberID = b.referenceid and a.personMemberID = ‘JCNPRH39681’ （A = B ,B = ‘号码’）

select a.personMemberID, * from chineseresume a,personmember b where a.personMemberID = b.referenceid and a.personMemberID = ‘JCNPRH39681’ and b.referenceid = ‘JCNPRH39681’ （A = B ,B = ‘号码’， A = ‘号码’）

select a.personMemberID, * from chineseresume a,personmember b where b.referenceid = ‘JCNPRH39681’ and a.personMemberID = ‘JCNPRH39681’ （B = ‘号码’， A = ‘号码’）

26，尽量使用exists代替select count(1)来判断是否存在记录，count函数只有在统计表中所有行数时使用，而且count(1)比count(*)更有效率。

27，尽量使用“>=”，不要使用“>”。

28，索引的使用规范：索引的创建要与应用结合考虑，建议大的OLTP表不要超过6个索引；尽可能的使用索引字段作为查询条件，尤其是聚簇索引，必要时可以通过index index_name来强制指定索引；避免对大表查询时进行table scan，必要时考虑新建索引；在使用索引字段作为条件时，如果该索引是联合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用；要注意索引的维护，周期性重建索引，重新编译存储过程。

29，下列SQL条件语句中的列都建有恰当的索引，但执行速度却非常慢：

SELECT * FROM record WHERE substrINg(card_no,1,4)=’5378’ (13秒)

SELECT * FROM record WHERE amount/30< 1000 （11秒）

SELECT * FROM record WHERE convert(char(10),date,112)=’19991201’ （10秒）

分析：

WHERE子句中对列的任何操作结果都是在SQL运行时逐列计算得到的，因此它不得不进行表搜索，而没有使用该列上面的索引；如果这些结果在查询编译时就能得到，那么就可以被SQL优化器优化，使用索引，避免表搜索，因此将SQL重写成下面这样：

SELECT * FROM record WHERE card_no like ‘5378%’ （< 1秒）

SELECT * FROM record WHERE amount< 1000*30 （< 1秒）

SELECT * FROM record WHERE date= ‘1999/12/01’ （< 1秒）

30，当有一批处理的插入或更新时，用批量插入或批量更新，绝不会一条条记录的去更新!

31，在所有的存储过程中，能够用SQL语句的，我绝不会用循环去实现!

(例如：列出上个月的每一天，我会用connect by去递归查询一下，绝不会去用循环从上个月第一天到最后一天)

32，选择最有效率的表名顺序(只在基于规则的优化器中有效)：

oracle 的解析器按照从右到左的顺序处理FROM子句中的表名，FROM子句中写在最后的表(基础表 driving table)将被最先处理，在FROM子句中包含多个表的情况下,你必须选择记录条数最少的表作为基础表。如果有3个以上的表连接查询, 那就需要选择交叉表(intersection table)作为基础表, 交叉表是指那个被其他表所引用的表.

33，提高GROUP BY语句的效率, 可以通过将不需要的记录在GROUP BY 之前过滤掉.下面两个查询返回相同结果，但第二个明显就快了许多.

低效:

SELECT JOB , AVG(SAL)

FROM EMP

GROUP BY JOB

HAVING JOB =’PRESIDENT’

OR JOB =’MANAGER’

高效:

SELECT JOB , AVG(SAL)

FROM EMP

WHERE JOB =’PRESIDENT’

OR JOB =’MANAGER’

GROUP BY JOB

34，sql语句用大写，因为oracle 总是先解析sql语句，把小写的字母转换成大写的再执行。

35，别名的使用，别名是大型数据库的应用技巧，就是表名、列名在查询中以一个字母为别名，查询速度要比建连接表快1.5倍。

36，避免死锁，在你的存储过程和触发器中访问同一个表时总是以相同的顺序;事务应经可能地缩短，在一个事务中应尽可能减少涉及到的数据量;永远不要在事务中等待用户输入。

37，避免使用临时表，除非却有需要，否则应尽量避免使用临时表，相反，可以使用表变量代替;大多数时候(99%)，表变量驻扎在内存中，因此速度比临时表更快，临时表驻扎在TempDb数据库中，因此临时表上的操作需要跨数据库通信，速度自然慢。

38，最好不要使用触发器，触发一个触发器，执行一个触发器事件本身就是一个耗费资源的过程;如果能够使用约束实现的，尽量不要使用触发器;不要为不同的触发事件(Insert，Update和Delete)使用相同的触发器;不要在触发器中使用事务型代码。

39，索引创建规则：

表的主键、外键必须有索引；

数据量超过300的表应该有索引；

经常与其他表进行连接的表，在连接字段上应该建立索引；

经常出现在Where子句中的字段，特别是大表的字段，应该建立索引；

索引应该建在选择性高的字段上；

索引应该建在小字段上，对于大的文本字段甚至超长字段，不要建索引；

复合索引的建立需要进行仔细分析，尽量考虑用单字段索引代替；

正确选择复合索引中的主列字段，一般是选择性较好的字段；

复合索引的几个字段是否经常同时以AND方式出现在Where子句中？单字段查询是否极少甚至没有？如果是，则可以建立复合索引；否则考虑单字段索引；

如果复合索引中包含的字段经常单独出现在Where子句中，则分解为多个单字段索引；

如果复合索引所包含的字段超过3个，那么仔细考虑其必要性，考虑减少复合的字段；

如果既有单字段索引，又有这几个字段上的复合索引，一般可以删除复合索引；

频繁进行数据操作的表，不要建立太多的索引；

删除无用的索引，避免对执行计划造成负面影响；

表上建立的每个索引都会增加存储开销，索引对于插入、删除、更新操作也会增加处理上的开销。另外，过多的复合索引，在有单字段索引的情况下，一般都是没有存在价值的；相反，还会降低数据增加删除时的性能，特别是对频繁更新的表来说，负面影响更大。

尽量不要对数据库中某个含有大量重复的值的字段建立索引。

40，mysql查询优化总结：使用慢查询日志去发现慢查询，使用执行计划去判断查询是否正常运行，总是去测试你的查询看看是否他们运行在最佳状态下。久而久之性能总会变化，避免在整个表上使用count(*),它可能锁住整张表，使查询保持一致以便后续相似的查询可以使用查询缓存

，在适当的情形下使用GROUP BY而不是DISTINCT，在WHERE, GROUP BY和ORDER BY子句中使用有索引的列，保持索引简单,不在多个索引中包含同一个列，有时候MySQL会使用错误的索引,对于这种情况使用USE INDEX，检查使用SQL_MODE=STRICT的问题，对于记录数小于5的索引字段，在UNION的时候使用LIMIT不是是用OR。

为了 避免在更新前SELECT，使用INSERT ON DUPLICATE KEY或者INSERT IGNORE ,不要用UPDATE去实现，不要使用 MAX,使用索引字段和ORDER BY子句，LIMIT M，N实际上可以减缓查询在某些情况下，有节制地使用，在WHERE子句中使用UNION代替子查询，在重新启动的MySQL，记得来温暖你的数据库，以确保您的数据在内存和查询速度快，考虑持久连接，而不是多个连接，以减少开销，基准查询，包括使用服务器上的负载，有时一个简单的查询可以影响其他查询，当负载增加您的服务器上，使用SHOW PROCESSLIST查看慢的和有问题的查询，在开发环境中产生的镜像数据中 测试的所有可疑的查询。

41，MySQL 备份过程:

从二级复制服务器上进行备份。在进行备份期间停止复制，以避免在数据依赖和外键约束上出现不一致。彻底停止MySQL，从数据库文件进行备份。

如果使用 MySQL dump进行备份，请同时备份二进制日志文件 C 确保复制没有中断。不要信任LVM 快照，这很可能产生数据不一致，将来会给你带来麻烦。为了更容易进行单表恢复，以表为单位导出数据 C 如果数据是与其他表隔离的。

当使用mysqldump时请使用 Copt。在备份之前检查和优化表。为了更快的进行导入，在导入时临时禁用外键约束。

为了更快的进行导入，在导入时临时禁用唯一性检测。在每一次备份后计算数据库，表以及索引的尺寸，以便更够监控数据尺寸的增长。

通过自动调度脚本监控复制实例的错误和延迟。定期执行备份。

42，查询缓冲并不自动处理空格，因此，在写SQL语句时，应尽量减少空格的使用，尤其是在SQL首和尾的空格(因为，查询缓冲并不自动截取首尾空格)。

43，member用mid做蔬M行分表方便查询么？一般的业务需求中基本上都是以username为查询依据，正常应当是username做hash取模来分表吧。分表的话 mysql 的partition功能就是干这个的，对代码是透明的；

在代码层面去实现貌似是不合理的。

44，我们应该为数据库里的每张表都设置一个ID做为其主键，而且最好的是一个INT型的（推荐使用UNSIGNED），并设置上自动增加的AUTO_INCREMENT标志。

45，在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。

无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。

46，MySQL查询可以启用高速查询缓存。这是提高数据库性能的有效Mysql优化方法之一。当同一个查询被执行多次时，从缓存中提取数据和直接从数据库中返回数据快很多。

47，EXPLAIN SELECT 查询用来跟踪查看效果

使用 EXPLAIN 关键字可以让你知道MySQL是如何处理你的SQL语句的。这可以帮你分析你的查询语句或是表结构的性能瓶颈。EXPLAIN 的查询结果还会告诉你你的索引主键被如何利用的，你的数据表是如何被搜索和排序的……等等，等等。

48，当只要一行数据时使用 LIMIT 1

当你查询表的有些时候，你已经知道结果只会有一条结果，但因为你可能需要去fetch游标，或是你也许会去检查返回的记录数。在这种情况下，加上 LIMIT 1 可以增加性能。这样一样，MySQL数据库引擎会在找到一条数据后停止搜索，而不是继续往后查少下一条符合记录的数据。

49,选择表合适存储引擎：

myisam: 应用时以读和插入操作为主，只有少量的更新和删除，并且对事务的完整性，并发性要求不是很高的。

Innodb：事务处理，以及并发条件下要求数据的一致性。除了插入和查询外，包括很多的更新和删除。（Innodb有效地降低删除和更新导致的锁定）。对于支持事务的InnoDB类型的表来说，影响速度的主要原因是AUTOCOMMIT默认设置是打开的，而且程序没有显式调用BEGIN 开始事务，导致每插入一条都自动提交，严重影响了速度。可以在执行sql前调用begin，多条sql形成一个事物（即使autocommit打开也可以），将大大提高性能。

50,优化表的数据类型,选择合适的数据类型：

原则：更小通常更好，简单就好，所有字段都得有默认值,尽量避免null。

例如：数据库表设计时候更小的占磁盘空间尽可能使用更小的整数类型.(mediumint就比int更合适)

比如时间字段：datetime和timestamp, datetime占用8个字节，而timestamp占用4个字节，只用了一半，而timestamp表示的范围是1970―2037适合做更新时间

MySQL可以很好的支持大数据量的存取，但是一般说来，数据库中的表越小，在它上面执行的查询也就会越快。

因此，在创建表的时候，为了获得更好的性能，我们可以将表中字段的宽度设得尽可能小。例如，

在定义邮政编码这个字段时，如果将其设置为CHAR(255),显然给数据库增加了不必要的空间，

甚至使用VARCHAR这种类型也是多余的，因为CHAR(6)就可以很好的完成任务了。同样的，如果可以的话，

我们应该使用MEDIUMINT而不是BIGIN来定义整型字段。

应该尽量把字段设置为NOT NULL，这样在将来执行查询的时候，数据库不用去比较NULL值。

对于某些文本字段，例如“省份”或者“性别”，我们可以将它们定义为ENUM类型。因为在MySQL中，ENUM类型被当作数值型数据来处理，

而数值型数据被处理起来的速度要比文本类型快得多。这样，我们又可以提高数据库的性能。

51， 字符串数据类型：char，varchar，text选择区别

52，任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。


---------------------------------------
数据库分表分库
https://my.oschina.net/u/3944379/blog/5034845

----------------------------------------------

linux运维必备的40个命令总结

1、删除0字节文件

find -type f -size 0 -exec rm -rf {} \;`
2、查看进程
按内存从大到小排列

PS -e -o "%C : %p : %z : %a"|sort -k5 -nr
3、按 CPU 利用率从大到小排列

ps -e -o "%C : %p : %z : %a"|sort -nr
4、打印 cache 里的URL

grep -r -a jpg /data/cache/* | strings | grep "http:" | awk -F'http:' '{print "http:"$2;}'
5、查看 http 的并发请求数及其 TCP 连接状态：

netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
6、 sed -i '/Root/s/no/yes/' /etc/ssh/sshd_config sed 在这个文里 Root 的一行，匹配 Root 一行，将 no 替换成 yes。

7、如何杀掉 MySQL 进程

ps aux |grep mysql |grep -v grep  |awk '{print $2}' |xargs kill -9 (从中了解到awk的用途)

killall -TERM mysqld

kill -9 `cat /usr/local/apache2/logs/httpd.pid`   试试查杀进程PID
8、显示运行 3 级别开启的服务:

ls /etc/rc3.d/S* |cut -c 15- (从中了解到cut的用途，截取数据)
9、如何在编写 SHELL 显示多个信息，用 EOF

cat << EOF
+--------------------------------------------------------------+
|       === Welcome to Tunoff services ===                |
+--------------------------------------------------------------+
EOF
10、for 的巧用（如给 MySQL 建软链接）

cd /usr/local/mysql/bin
for i in *
do ln /usr/local/mysql/bin/$i /usr/bin/$i
done
11、取 IP 地址

ifconfig eth0 |grep "inet addr:" |awk '{print $2}'| cut -c 6-  
或者
ifconfig | grep 'inet addr:'| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $1}'
12、内存的大小:

free -m |grep "Mem" | awk '{print $2}'
13

netstat -an -t | grep ":80" | grep ESTABLISHED | awk '{printf "%s %s\n",$5,$6}' | sort
14、查看 Apache 的并发请求数及其 TCP 连接状态：

netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
15、因为同事要统计一下服务器下面所有的 jpg 的文件的大小，写了个 SHELL 给他来统计。原来用 xargs 实现，但他一次处理一部分。搞的有多个总和……，下面的命令就能解决。

find / -name *.jpg -exec wc -c {} \;|awk '{print $1}'|awk '{a+=$1}END{print a}'
CPU 的数量（多核算多个CPU，cat /proc/cpuinfo |grep -c processor）越多，系统负载越低，每秒能处理的请求数也越多。

16、CPU负载

cat /proc/loadavg
检查前三个输出值是否超过了系统逻辑 CPU 的4倍。

17、 CPU负载

mpstat 1 1
检查 %idle 是否过低（比如小于5%）。

18、内存空间

free
检查 free 值是否过低，也可以用 # cat /proc/meminfo

19、SWAP 空间

free
检查 swap used 值是否过高，如果 swap used 值过高，进一步检查 swap 动作是否频繁：

vmstat 1 5
观察 si 和 so 值是否较大

20、磁盘空间

df -h
检查是否有分区使用率（Use%）过高（比如超过90%）如发现某个分区空间接近用尽，可以进入该分区的挂载点，用以下命令找出占用空间最多的文件或目录：

du -cks * | sort -rn | head -n 10
21、磁盘 I/O 负载

iostat -x 1 2
检查I/O使用率（%util）是否超过 100%

22、网络负载

sar -n DEV
检查网络流量（rxbyt/s, txbyt/s）是否过高

23、网络错误

netstat -i
检查是否有网络错误（drop fifo colls carrier），也可以用命令：# cat /proc/net/dev

24、网络连接数目

netstat -an | grep -E “^(tcp)” | cut -c 68- | sort | uniq -c | sort -n
25、进程总数

ps aux | wc -l
检查进程个数是否正常 (比如超过250)

26、可运行进程数目

vmwtat 1 5
列给出的是可运行进程的数目，检查其是否超过系统逻辑 CPU 的 4 倍

27、进程

top -id 1
观察是否有异常进程出现。

28、网络状态，检查DNS，网关等是否可以正常连通

29、用户

who | wc -l
检查登录用户是否过多 (比如超过50个) 也可以用命令：# uptime。

30、系统日志

# cat /var/log/rflogview/*errors
检查是否有异常错误记录 也可以搜寻一些异常关键字，例如：

grep -i error /var/log/messages
grep -i fail /var/log/messages
31、核心日志

dmesg
检查是否有异常错误记录。

32、系统时间

date
检查系统时间是否正确。

33、打开文件数目

lsof | wc -l
检查打开文件总数是否过多。

34、日志

# logwatch Cprint
配置 /etc/log.d/logwatch.conf，将 Mailto 设置为自己的 email 地址，启动 mail 服务(sendmail或者postfix)，这样就可以每天收到日志报告了。
缺省 logwatch 只报告昨天的日志，可以用 # logwatch Cprint Crange all 获得所有的日志分析结果。
可以用 # logwatch Cprint Cdetail high 获得更具体的日志分析结果(而不仅仅是出错日志)。
35、杀掉80端口相关的进程

lsof -i :80|grep -v “ID”|awk ‘{print “kill -9”,$2}’|sh
36、清除僵死进程

ps -eal | awk '{ if ($2 == "Z") {print $4}}' | kill -9
37、tcpdump 抓包，用来防止80端口被人攻击时可以分析数据

tcpdump -c 10000 -i eth0 -n dst port 80 > /root/pkts
38、然后检查IP的重复数并从小到大排序 注意 “-t\ +0” 中间是两个空格

# less pkts | awk {'printf $3"\n"'} | cut -d. -f 1-4 | sort | uniq -c | awk {'printf $1" "$2"\n"'} | sort -n -t\ +0
39、查看有多少个活动的 php-cgi 进程

netstat -anp | grep php-cgi | grep ^tcp | wc -l
40、查看系统自启动的服务

chkconfig --list | awk '{if ($5=="3:on") print $1}'
41、kudzu 查看网卡型号

kudzu --probe --class=network
常用正则表达式
1.匹配中文字符的正则表达式： [\u4e00-\u9fa5]

评注：匹配中文还真是个头疼的事，有了这个表达式就好办了

2.匹配双字节字符(包括汉字在内)：1

评注：可以用来计算字符串的长度（一个双字节字符长度计2，ASCII字符计1）

3.匹配空白行的正则表达式：\n\s*\r

评注：可以用来删除空白行

4.匹配 HTML 标记的正则表达式：<(\S?)2>.?</\1>|<.? />

评注：网上流传的版本太糟糕，上面这个也仅仅能匹配部分，对于复杂的嵌套标记依旧无能为力

5.匹配首尾空白字符的正则表达式：^\s|\s$

评注：可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式

6.匹配Email地址的正则表达式：

\w+([-+.]\w+)*@\w+([-.]\w+)*\.\w+([-.]\w+)*
评注：表单验证时很实用

7.匹配网址URL的正则表达式：[a-zA-z]+://3*

评注：网上流传的版本功能很有限，上面这个基本可以满足需求

8.匹配帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：

^[a-zA-Z][a-zA-Z0-9_]{4,15}$
评注：表单验证时很实用

9.匹配国内电话号码：\d{3}-\d{8}|\d{4}-\d{7}

评注：匹配形式如 0511-4405222 或 021-87888822

10.匹配腾讯QQ号：1-9{4,}

评注：腾讯QQ号从10000开始

11.匹配中国邮政编码：[1-9]\d{5}(?!\d)

评注：中国邮政编码为6位数字

12.匹配×××：\d{15}|\d{18}

评注：中国的×××为15位或18位

13.匹配ip地址：\d+.\d+.\d+.\d+

评注：提取 IP 地址时有用

14.匹配特定数字：

^[1-9]\d*$　 　//匹配正整数
^-[1-9]\d*$ 　//匹配负整数
^-?[1-9]\d*$　　//匹配整数
^[1-9]\d*|0$　//匹配非负整数（正整数 + 0）
^-[1-9]\d*|0$　　//匹配非正整数（负整数 + 0）
^[1-9]\d*\.\d*|0\.\d*[1-9]\d*$　　//匹配正浮点数
^-([1-9]\d*\.\d*|0\.\d*[1-9]\d*)$　//匹配负浮点数
^-?([1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0)$　//匹配浮点数
^[1-9]\d*\.\d*|0\.\d*[1-9]\d*|0?\.0+|0$　　//匹配非负浮点数（正浮点数 + 0）
^(-([1-9]\d*\.\d*|0\.\d*[1-9]\d*))|0?\.0+|0$　//匹配非正浮点数（负浮点数 + 0）
评注：处理大量数据时有用，具体应用时注意修正

15.匹配特定字符串：

^[A-Za-z]+$　//匹配由26个英文字母组成的字符串
^[A-Z]+$　//匹配由26个英文字母的大写组成的字符串
^[a-z]+$　//匹配由26个英文字母的小写组成的字符串
^[A-Za-z0-9]+$　//匹配由数字和26个英文字母组成的字符串
^\w+$　//匹配由数字、26个英文字母或者下划线组成的字符串

mysql中的聚集索引、非聚集索引、聚簇索引、稀疏索引、稠密索引

https://blog.csdn.net/guzhangyu12345/article/details/96423704

常见问题
https://zhuanlan.zhihu.com/p/107883599?utm_source=wechat_session







